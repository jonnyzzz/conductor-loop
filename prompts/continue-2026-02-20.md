# Conductor Loop - Continue Work Session (2026-02-20)

You are an orchestrator agent continuing work on the Conductor Loop project.

**Project root**: <project-root>
**Workflow guide**: <project-root>/docs/workflow/THE_PROMPT_v5.md
**Plan**: <project-root>/docs/workflow/THE_PLAN_v5.md
**Message Bus**: <project-root>/MESSAGE-BUS.md
**Issues**: <project-root>/docs/dev/issues.md
**Run-agent script**: <project-root>/run-agent.sh
**Runs dir**: <project-root>/runs

## Mandatory First Steps

1. Read <project-root>/docs/workflow/THE_PROMPT_v5.md — this is your primary workflow guide
2. Read <project-root>/AGENTS.md — project conventions
3. Read <project-root>/MESSAGE-BUS.md — understand current project state
4. Read <project-root>/docs/dev/issues.md — understand open blockers
5. Read <project-root>/docs/workflow/THE_PLAN_v5.md — understand what was planned and what remains

## Current Project State (as of 2026-02-20)

- **Build**: `go build ./...` passes (verified)
- **Tests**: Most pass. **CRITICAL**: `test/performance` FAILS:
  - `TestMessageBusThroughput`: 99.80 msg/sec (threshold requires 100+)
  - `TestRunCreationThroughput`: 39.80 runs/sec (threshold requires 40+)
- **Stages 1–5**: Implemented (Core Infrastructure, Agent System, Runner, API/Frontend, Tests)
- **Stage 6** (Documentation): `docs-user` ✅, `docs-examples` ✅, `docs-dev` — exists but may be incomplete
- **Last active session**: 2026-02-05 (see MESSAGE-BUS.md)

## Your Goals (in priority order)

### Priority 1: Fix Failing Performance Tests
The file `<project-root>/test/performance/benchmark_test.go` has two failing tests.
- Investigate whether the threshold is too strict (borderline: 99.80 vs 100, 39.80 vs 40) OR whether actual performance needs improvement
- Fix by either adjusting thresholds (if they are arbitrary) or improving actual message bus / run creation performance
- After fix: run `go test ./test/performance/...` to confirm green

### Priority 2: Complete Stage 6 Documentation (docs-dev)
- Review <project-root>/docs/dev/ — files exist, verify they are complete and accurate against the implementation
- Files: adding-agents.md, agent-protocol.md, architecture.md, contributing.md, development-setup.md, message-bus.md, ralph-loop.md, storage-layout.md, subsystems.md, testing.md
- Cross-check each doc against the actual implementation in <project-root>/internal/ and <project-root>/pkg/
- Fix any inaccuracies, fill in gaps, make sure they reflect the real code

### Priority 3: Dog-food the System
- Build the conductor binary: `go build -o conductor ./cmd/conductor`
- Build run-agent: `go build -o run-agent ./cmd/run-agent`
- Start the conductor server and use it to run an actual sub-task (e.g., a small code review or doc improvement task on the project itself)
- This tests the system end-to-end and validates it actually works
- Document any issues found in <project-root>/docs/dev/issues.md

### Priority 4: Review Implementation and Collect Questions
- Do a thorough review of key implementation files
- Any open questions or design uncertainties: write them to `<project-root>/docs/dev/questions.md`
- Focus on: Ralph Loop edge cases, message bus concurrency, agent backend reliability, API correctness

## Agent Execution Instructions

Use `<project-root>/run-agent.sh` to spawn sub-agents for parallel work.

For each sub-agent task:
1. Write a prompt file to `<project-root>/prompts/task-<name>.md`
2. Run: `cd <project-root> && ./run-agent.sh claude <project-root> prompts/task-<name>.md`
3. Monitor with: `cd <project-root> && uv run python monitor-agents.py`

Suggested parallel sub-agents:
- **fix-perf-tests**: Investigate and fix the two failing performance benchmarks
- **review-dev-docs**: Review and improve docs/dev/ against actual implementation
- **dogfood-test**: Build binaries, start conductor, run a test task end-to-end

## Communication

- Log ALL significant actions, decisions, and results to <project-root>/MESSAGE-BUS.md (append-only)
- Log blockers to <project-root>/docs/dev/issues.md
- Collect open questions in <project-root>/docs/dev/questions.md

## Success Criteria

This session is successful when:
1. `go test ./...` shows NO failures (all green including performance tests)
2. docs/dev/ files are accurate and complete
3. Conductor binary runs and successfully executes at least one sub-task
4. MESSAGE-BUS.md has a summary of all work done
5. Any open questions are captured in docs/dev/questions.md

Start now. Read the files, assess the state, and spawn sub-agents in parallel.
