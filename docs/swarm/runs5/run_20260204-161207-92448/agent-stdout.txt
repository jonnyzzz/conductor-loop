Perfect. Now I have all the information I need to provide my analysis. Let me structure my findings:

---

## 1) External Facts Check

**Verified Claims:**

- **OpenCode**: Confirmed as a real open-source AI coding agent CLI tool that supports multiple LLM providers including xAI. OpenCode can be configured via provider settings to use xAI's Grok models. ✓
  
- **xAI Integration**: xAI's Grok Code Fast 1 model is specifically designed for agentic coding and is supported by OpenCode as a launch partner. ✓

- **xAI API**: xAI provides a documented REST API at docs.x.ai with multiple Grok model variants including grok-code-fast-1 (optimized for coding). ✓

- **Token-based access**: xAI API requires API keys for authentication, consistent with the config.hcl pattern mentioned. ✓

**Key Finding**: The spec correctly identifies OpenCode as the integration path for xAI, and the approach (configure OpenCode to use xAI models via token) is technically sound. The decision to defer this post-MVP is reasonable given it requires OpenCode integration setup.

**Sources:**
- [OpenCode | The open source AI coding agent](https://opencode.ai/)
- [Providers | OpenCode](https://opencode.ai/docs/providers/)
- [xAI API](https://docs.x.ai/docs/overview)
- [Models and Pricing | xAI](https://docs.x.ai/docs/models)

---

## 2) Spec Updates

### subsystem-agent-backend-xai.md

**Current state**: The spec has been updated to reflect the answered questions but lacks specificity.

**Proposed updates:**

- **Line 4**: Change "This work is deferred post-MVP" → "Integration is deferred post-MVP pending OpenCode adapter implementation"

- **Line 8**: Change "Document the intended future integration path (OpenCode + xAI)" → "Document the integration approach using OpenCode CLI configured for xAI models"

- **Line 14**: Expand "Use OpenCode agent configured to target xAI models (only if xAI token is provided)" to:
  ```
  Use OpenCode CLI (opencode.ai) configured to target xAI's Grok models via provider flags.
  - Model selection: Default to grok-code-fast-1 for coding tasks (optimized for agentic coding).
  - Configuration: Pass xAI provider and model parameters to OpenCode via CLI flags or config file.
  - Token requirement: xAI API key must be present in config.hcl; backend is disabled if absent.
  ```

- **Line 15**: Remove "Default to the best available xAI model when enabled" (redundant, covered above)

- **Line 23**: Expand "API key storage follows the same config.hcl pattern as other backends (token required to enable xAI)" to:
  ```
  - API key stored in config.hcl under xai.api_token (or @file reference).
  - Injected as XAI_API_KEY environment variable for OpenCode process.
  - Backend is skipped in rotation if token is missing/empty.
  ```

- **Add new section** after Environment/Config:
  ```
  ## OpenCode Integration
  - OpenCode CLI must be installed and available in PATH.
  - run-agent adapter passes provider configuration to OpenCode:
    - --provider xai
    - --model grok-code-fast-1 (or config override)
    - --api-key $XAI_API_KEY
  - Streaming output handled via OpenCode's native output format.
  
  ## Implementation Status
  - Post-MVP: OpenCode adapter implementation required.
  - Deferred until core runner and other backends are stable.
  ```

### TIPICS.md

**Current state**: Topic 8 mentions xAI is deferred but doesn't specify OpenCode.

**Proposed update:**

- **Line 106**: Change "xAI integration is deferred post-MVP with OpenCode planned" → "xAI integration is deferred post-MVP; will use OpenCode CLI configured for xAI's Grok models (grok-code-fast-1)"

---

## 3) Questions to Remove/Resolve

### subsystem-agent-backend-xai-QUESTIONS.md

**Q1**: "Which xAI model/agent should be targeted first for coding tasks, and what is the invocation method (API vs CLI)?"

**Resolution**: ANSWERED. Use OpenCode CLI (which wraps xAI API) with grok-code-fast-1 model. Post-MVP implementation deferred.

**Action**: Remove this question and migrate decision to spec.

---

**Q2**: "Does the xAI backend require additional tool-calling or sandbox capabilities that need to be surfaced in run-agent?"

**Resolution**: ANSWERED. No sandboxing; full tool access like other backends. This is consistent with TIPICS.md Topic 4 ("No enforced sandbox").

**Action**: Remove this question (already aligned with global policy).

---

**Q3** (NEW, from QUESTIONS file line 1): "How will OpenCode be configured to use xAI models when the integration is enabled post-MVP?"

**Resolution**: ANSWERED in commit 43e152d. OpenCode will receive provider/model flags; token required; deferred post-MVP.

**Action**: Remove this question and migrate details to spec (see section 2 above).

---

## 4) New Open Questions

### subsystem-agent-backend-xai-QUESTIONS.md

Since all current questions have been answered and the answers have been incorporated into the spec update proposals above, **NO new open questions are needed at this time**.

The spec is now well-defined for post-MVP implementation:
- Tool: OpenCode CLI
- Model: grok-code-fast-1
- Config: Standard token pattern
- Behavior: No sandboxing, full tool access

The only remaining work is implementation (OpenCode adapter in run-agent), which is explicitly post-MVP.

**Recommendation**: After applying spec updates from section 2, the QUESTIONS file can be **deleted** or reduced to a single placeholder:

```markdown
# Agent Backend: xAI - Questions

*All implementation questions resolved. Integration deferred post-MVP. See subsystem-agent-backend-xai.md for decided approach.*
```

---

## 5) New Docs/Topics Suggested

**No new dedicated documents needed.**

The xAI integration is straightforward and fits cleanly within the existing subsystem-agent-backend-xai.md spec. The approach (OpenCode CLI wrapper) is similar to other agent backends.

**However, consider:**

1. **Cross-reference enhancement**: Add xAI/OpenCode to the "Agent Backend Integrations" section in TIPICS.md Topic 8 with more detail after spec is updated.

2. **OpenCode dependency tracking**: If OpenCode becomes a shared dependency for multiple backends (e.g., if Perplexity also uses OpenCode in the future), consider a new topic or subsystem spec for "OpenCode Integration Layer" to avoid duplication. **Not needed yet** — wait until second OpenCode-based backend emerges.

---

## Summary

All questions for xAI backend have been answered. The integration approach (OpenCode CLI + grok-code-fast-1) is well-defined and technically verified. The spec should be updated with concrete invocation details and the QUESTIONS file can be cleared. No contradictions found; decisions are consistent with ideas.md (post-MVP deferral) and TIPICS.md (no sandboxing, token-based enablement).
