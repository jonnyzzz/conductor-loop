Perfect! Now I have comprehensive information. Let me compile the analysis:

## Topic 8: Agent Backend Integrations - Review Analysis

### 1) External Facts Check

**Verified via web search (2026 sources):**

✅ **Claude Code CLI** - Confirmed flags:
- `--permission-mode bypassPermissions` ✓ (correct)
- `--input-format text --output-format text` ❌ (incorrect - should use `-p` for print mode and `--output-format json|stream-json` for structured output)
- `--tools default` ⚠️ (partial - should use `--allowedTools` or `--disallowedTools` for tool management)
- Environment variable: `ANTHROPIC_API_KEY` ✓

**Issue:** The spec lists `--input-format text` which is not documented; should use `-p` flag instead.

✅ **Codex/GitHub Copilot CLI** - Verified:
- Command is `copilot` not `codex` ❌
- `--allow-all` and `--yolo` flags for bypassing permissions ✓
- No `--dangerously-bypass-approvals-and-sandbox` flag found ❌
- Model selection via `--model gpt-5.2-codex` ✓

**Issue:** The spec refers to "Codex CLI" but the actual tool is GitHub Copilot CLI with `copilot` command.

✅ **Gemini CLI** - Verified:
- Auto-approve mode exists ✓
- No `--approval-mode yolo` flag documented ❌ (uses settings-based auto-approve checkbox)
- No `--screen-reader true` flag found ❌
- Tool restrictions via JSON config, not CLI flags ⚠️

**Issue:** The spec's flags don't match actual Gemini CLI interface.

✅ **Perplexity API** - Verified:
- Native REST API ✓
- `sonar-pro` and `sonar-reasoning-pro` models exist ✓
- Supports coding tasks ✓
- Streaming available ✓

✅ **xAI/Grok** - Verified:
- OpenCode integration exists ✓
- Launch partner for `grok-code-fast-1` ✓
- xAI API available ✓
- Tool support including web search ✓

### 2) TIPICS Updates

**Topic 8 should be expanded with:**

- Add decision: Claude CLI uses `-p` flag for non-interactive mode, not `--input-format text`.
- Add decision: Codex backend refers to GitHub Copilot CLI (command: `copilot`), not a standalone "codex" binary.
- Add decision: Gemini CLI uses settings-based auto-approve, not `--approval-mode yolo` CLI flag.
- Add decision: Environment variable mapping per backend is documented in question files (ANTHROPIC_API_KEY for Claude, GEMINI_API_KEY for Gemini, etc.).
- Update decision: xAI integration via OpenCode is viable post-MVP (no longer "deferred" - should be "planned with OpenCode").
- Remove open question: "Backend-specific env var mappings" - should be decided and documented per backend.
- Add open question: "Should run-agent wrap CLI tools with normalized flags, or adapt to each tool's native interface?"

### 3) Spec Updates

**subsystem-agent-backend-claude.md:**
- Line 16: Change `--input-format text --output-format text` to `-p --output-format stream-json`
- Line 17: Update comment to clarify `-p` enables non-interactive/print mode
- Line 29: Add explicit statement: "run-agent does not set a model; host CLI defaults/config are used."
- Add section: "Environment Variables" - document ANTHROPIC_API_KEY requirement

**subsystem-agent-backend-codex.md:**
- Title: Change "Codex" to "GitHub Copilot CLI (Codex)"
- Line 1: Update overview to clarify this is GitHub Copilot CLI
- Line 16: Change `codex exec --dangerously-bypass-approvals-and-sandbox` to `copilot --allow-all --yolo` or similar verified flags
- Line 28: Add: "No sandboxing enforced; full tool access is required (keep `--allow-all` or similar flags)."
- Line 29: Add explicit note: "run-agent does not override model/reasoning settings; host CLI defaults apply."

**subsystem-agent-backend-gemini.md:**
- Line 16: Replace `--approval-mode yolo` with documentation of auto-approve settings or equivalent config approach
- Line 16: Remove `--screen-reader true` (not documented)
- Add section explaining Gemini uses settings JSON for tool permissions, not CLI flags
- Line 29: Add explicit statement: "run-agent does not set a model; host CLI defaults/config are used."

**subsystem-agent-backend-perplexity.md:**
- Line 28: Change "use the most capable model by default" to "use sonar-reasoning-pro by default for coding tasks"
- Add section: "Streaming" - document that Perplexity API supports streaming for liveness updates

**subsystem-agent-backend-xai.md:**
- Line 4: Change "deferred post-MVP" to "planned for post-MVP via OpenCode integration"
- Line 15: Update to: "Use OpenCode CLI configured with xAI provider (grok-code-fast-1 or grok-beta models)"
- Add note: OpenCode supports xAI as a launch partner with full tool access and streaming

**subsystem-runner-orchestration.md:**
- Line 86: Add explicit note: "xAI integration planned via OpenCode (see subsystem-agent-backend-xai.md)"

### 4) Questions to Remove/Resolve

**subsystem-agent-backend-claude-QUESTIONS.md:**

❌ Remove Q: "Which Claude model should be the default?" 
- **Resolution:** Already answered - use CLI defaults/host config; no model override in run-agent.

❌ Remove Q: "Should tool access be restricted beyond --tools default?"
- **Resolution:** Already answered - full tool access with `--tools default` and `--permission-mode bypassPermissions`.

**New resolved question to add then remove:**
- Q: What are the correct Claude CLI flags for non-interactive mode?
- A: Use `-p --output-format stream-json --permission-mode bypassPermissions --tools default`.

**subsystem-agent-backend-codex-QUESTIONS.md:**

✅ Add and resolve:
- Q: What is the actual command name for the Codex backend?
- A: GitHub Copilot CLI (`copilot` command), not standalone `codex`. Use `copilot --allow-all` or similar for full permissions.

- Q: What environment variable does GitHub Copilot CLI expect for authentication?
- A: `GITHUB_TOKEN` or OAuth flow; verify in GitHub Copilot CLI docs.

**subsystem-agent-backend-gemini-QUESTIONS.md:**

✅ Keep Q: "What environment variable name does the Gemini CLI expect?" but update answer:
- **Update A:** GEMINI_API_KEY (or GOOGLE_AI_API_KEY) based on Google AI SDK patterns.

❌ Remove Q: "Does the Gemini CLI support streaming/unbuffered stdout?"
- **Resolution:** Gemini CLI supports streaming; should enable unbuffered output if needed.

**New question:**
- Q: How should run-agent configure Gemini CLI auto-approve mode since there's no `--approval-mode` flag?
- Proposed default: Use Gemini settings JSON or environment config to enable auto-approve.
- A: TBD.

**subsystem-agent-backend-perplexity-QUESTIONS.md:**

✅ Resolve Q: "Should the Perplexity adapter use streaming responses?"
- **Update A:** Yes, Perplexity API supports streaming; adapter should use streaming for liveness updates.

✅ Resolve Q: "How should Perplexity citations be represented?"
- **Update A:** Append a "References" or "Citations" section after main response; Perplexity API provides citations natively.

**subsystem-agent-backend-xai-QUESTIONS.md:**

✅ Resolve Q: "How will OpenCode be configured to use xAI models?"
- **Update A:** OpenCode natively supports xAI via the `/models` command to select grok-beta or grok-code-fast-1. Pass xAI API key to OpenCode; use `--model` flag or OpenCode config.

### 5) New Open Questions

**subsystem-agent-backend-claude-QUESTIONS.md:**
- Q: Should run-agent validate ANTHROPIC_API_KEY before spawning Claude CLI, or let CLI fail on missing credentials? | Proposed default: Let CLI fail fast (no proactive validation in MVP). | A: TBD.

**subsystem-agent-backend-codex-QUESTIONS.md:**
- Q: What environment variable name does GitHub Copilot CLI expect for API credentials (GITHUB_TOKEN, COPILOT_TOKEN, etc.)? | Proposed default: GITHUB_TOKEN. | A: TBD.
- Q: Should run-agent use `copilot --yolo` or `copilot --allow-all` for full permissions mode? | Proposed default: Test both and document the working flag. | A: TBD.

**subsystem-agent-backend-gemini-QUESTIONS.md:**
- Q: How should run-agent enable Gemini auto-approve mode without CLI flags? | Proposed default: Document required Gemini settings JSON configuration or use environment-based config. | A: TBD.

**subsystem-agent-backend-perplexity-QUESTIONS.md:**
- Q: What Perplexity API endpoint should the adapter use (completions, chat, search)? | Proposed default: Use chat completions API with sonar-reasoning-pro model. | A: TBD.

**subsystem-agent-backend-xai-QUESTIONS.md:**
- Q: Should xAI integration use OpenCode CLI or direct xAI API calls? | Proposed default: Use OpenCode CLI to leverage existing tool/MCP integration. | A: TBD.

---

## Summary

**Critical issues found:**
1. Claude CLI flags in spec don't match actual CLI (needs `-p` not `--input-format text`)
2. "Codex" is actually "GitHub Copilot CLI" with different command syntax
3. Gemini CLI doesn't support documented flags; uses settings-based config
4. Several resolved questions in QUESTIONS files should be removed

**Positive findings:**
- Perplexity API integration plan is sound
- xAI/OpenCode integration is viable and well-documented
- Overall backend strategy is coherent

**Recommendations:**
1. Update all backend specs with correct CLI flags from 2026 documentation
2. Align TIPICS.md with resolved questions
3. Add environment variable mapping decisions to TIPICS.md Topic 8
4. Clarify that run-agent relies on host CLI defaults for model selection

Sources:
- [Claude Code CLI Reference](https://code.claude.com/docs/en/cli-reference)
- [GitHub Copilot CLI Documentation](https://docs.github.com/en/copilot/how-tos/use-copilot-agents/use-copilot-cli)
- [Gemini CLI Documentation](https://developers.google.com/gemini-code-assist/docs/gemini-cli)
- [Perplexity API Models](https://docs.perplexity.ai/getting-started/models/models/sonar-reasoning-pro)
- [xAI Grok OpenCode Integration](https://github.com/opencode-ai/opencode/pull/307)
